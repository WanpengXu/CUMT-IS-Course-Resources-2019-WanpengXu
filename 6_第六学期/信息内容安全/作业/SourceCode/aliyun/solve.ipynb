{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import LabelBinarizer,LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/'\n",
    "train = pd.read_csv(path + 'security_train.csv')\n",
    "test = pd.read_csv(path + 'security_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  \n",
    "\n",
    "class _Data_Preprocess:\n",
    "    def __init__(self):\n",
    "        self.int8_max = np.iinfo(np.int8).max\n",
    "        self.int8_min = np.iinfo(np.int8).min\n",
    "\n",
    "        self.int16_max = np.iinfo(np.int16).max\n",
    "        self.int16_min = np.iinfo(np.int16).min\n",
    "\n",
    "        self.int32_max = np.iinfo(np.int32).max\n",
    "        self.int32_min = np.iinfo(np.int32).min\n",
    "\n",
    "        self.int64_max = np.iinfo(np.int64).max\n",
    "        self.int64_min = np.iinfo(np.int64).min\n",
    "\n",
    "        self.float16_max = np.finfo(np.float16).max\n",
    "        self.float16_min = np.finfo(np.float16).min\n",
    "\n",
    "        self.float32_max = np.finfo(np.float32).max\n",
    "        self.float32_min = np.finfo(np.float32).min\n",
    "\n",
    "        self.float64_max = np.finfo(np.float64).max\n",
    "        self.float64_min = np.finfo(np.float64).min\n",
    "\n",
    "    def _get_type(self, min_val, max_val, types):\n",
    "        if types == 'int':\n",
    "            if max_val <= self.int8_max and min_val >= self.int8_min:\n",
    "                return np.int8\n",
    "            elif max_val <= self.int16_max <= max_val and min_val >= self.int16_min:\n",
    "                return np.int16\n",
    "            elif max_val <= self.int32_max and min_val >= self.int32_min:\n",
    "                return np.int32\n",
    "            return None\n",
    "\n",
    "        elif types == 'float':\n",
    "            if max_val <= self.float16_max and min_val >= self.float16_min:\n",
    "                return np.float16\n",
    "            if max_val <= self.float32_max and min_val >= self.float32_min:\n",
    "                return np.float32\n",
    "            if max_val <= self.float64_max and min_val >= self.float64_min:\n",
    "                return np.float64\n",
    "            return None\n",
    "\n",
    "    def _memory_process(self, df):\n",
    "        init_memory = df.memory_usage().sum() / 1024 ** 2 / 1024\n",
    "        print('Original data occupies {} GB memory.'.format(init_memory))\n",
    "        df_cols = df.columns\n",
    "\n",
    "          \n",
    "        for col in tqdm_notebook(df_cols):\n",
    "            try:\n",
    "                if 'float' in str(df[col].dtypes):\n",
    "                    max_val = df[col].max()\n",
    "                    min_val = df[col].min()\n",
    "                    trans_types = self._get_type(min_val, max_val, 'float')\n",
    "                    if trans_types is not None:\n",
    "                        df[col] = df[col].astype(trans_types)\n",
    "                elif 'int' in str(df[col].dtypes):\n",
    "                    max_val = df[col].max()\n",
    "                    min_val = df[col].min()\n",
    "                    trans_types = self._get_type(min_val, max_val, 'int')\n",
    "                    if trans_types is not None:\n",
    "                        df[col] = df[col].astype(trans_types)\n",
    "            except:\n",
    "                print(' Can not do any process for column, {}.'.format(col)) \n",
    "        afterprocess_memory = df.memory_usage().sum() / 1024 ** 2 / 1024\n",
    "        print('After processing, the data occupies {} GB memory.'.format(afterprocess_memory))\n",
    "        return df\n",
    "\n",
    "memory_process = _Data_Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# （字符串转化为数字）\n",
    "unique_api = train['api'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api2index = {item:(i+1) for i,item in enumerate(unique_api)}\n",
    "index2api = {(i+1):item for i,item in enumerate(unique_api)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['api_idx'] = train['api'].map(api2index)\n",
    "test['api_idx']  = test['api'].map(api2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取每个文件对应的字符串序列\n",
    "def get_sequence(df,period_idx):\n",
    "    seq_list = []\n",
    "    for _id,begin in enumerate(period_idx[:-1]):\n",
    "        seq_list.append(df.iloc[begin:period_idx[_id+1]]['api_idx'].values)\n",
    "    seq_list.append(df.iloc[period_idx[-1]:]['api_idx'].values)\n",
    "    return seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_period_idx = train.file_id.drop_duplicates(keep='first').index.values\n",
    "test_period_idx  = test.file_id.drop_duplicates(keep='first').index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train[['file_id','label']].drop_duplicates(keep='first')\n",
    "test_df  = test[['file_id']].drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['seq'] = get_sequence(train,train_period_idx)\n",
    "test_df['seq']  = get_sequence(test,test_period_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Lambda, Embedding, Dropout, Activation,GRU,Bidirectional\n",
    "from keras.layers import Conv1D,Conv2D,MaxPooling2D,GlobalAveragePooling1D,GlobalMaxPooling1D, MaxPooling1D, Flatten\n",
    "from keras.layers import CuDNNGRU, CuDNNLSTM, SpatialDropout1D\n",
    "from keras.layers.merge import concatenate, Concatenate, Average, Dot, Maximum, Multiply, Subtract, average\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, LatentDirichletAllocation\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers.wrappers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextCNN(max_len,max_cnt,embed_size, num_filters,kernel_size,conv_action, mask_zero):\n",
    "    \n",
    "    _input = Input(shape=(max_len,), dtype='int32')\n",
    "    _embed = Embedding(max_cnt, embed_size, input_length=max_len, mask_zero=mask_zero)(_input)\n",
    "    _embed = SpatialDropout1D(0.15)(_embed)\n",
    "    warppers = []\n",
    "    \n",
    "    for _kernel_size in kernel_size:\n",
    "        conv1d = Conv1D(filters=num_filters, kernel_size=_kernel_size, activation=conv_action)(_embed)\n",
    "        warppers.append(GlobalMaxPooling1D()(conv1d))\n",
    "                        \n",
    "    fc = concatenate(warppers)\n",
    "    fc = Dropout(0.5)(fc)\n",
    "    #fc = BatchNormalization()(fc)\n",
    "    fc = Dense(256, activation='relu')(fc)\n",
    "    fc = Dropout(0.25)(fc)\n",
    "    #fc = BatchNormalization()(fc) \n",
    "    preds = Dense(8, activation = 'softmax')(fc)\n",
    "    \n",
    "    model = Model(inputs=_input, outputs=preds)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.get_dummies(train_df.label).values\n",
    "train_seq    = pad_sequences(train_df.seq.values, maxlen = 6000)\n",
    "test_seq     = pad_sequences(test_df.seq.values, maxlen = 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,KFold \n",
    "skf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len     = 6000\n",
    "max_cnt     = 295\n",
    "embed_size  = 256\n",
    "num_filters = 64\n",
    "kernel_size = [2,4,6,8,10,12,14]\n",
    "conv_action = 'relu'\n",
    "mask_zero   = False\n",
    "TRAIN       = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: \n",
      "2778 11109\n",
      "Train on 11109 samples, validate on 2778 samples\n",
      "Epoch 1/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.8213 - accuracy: 0.7297 - val_loss: 0.4469 - val_accuracy: 0.8521\n",
      "Epoch 2/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.4814 - accuracy: 0.8508 - val_loss: 0.3879 - val_accuracy: 0.8719\n",
      "Epoch 3/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.4290 - accuracy: 0.8652 - val_loss: 0.3721 - val_accuracy: 0.8877\n",
      "Epoch 4/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.3824 - accuracy: 0.8787 - val_loss: 0.3620 - val_accuracy: 0.8844\n",
      "Epoch 5/100\n",
      "11109/11109 [==============================] - 31s 3ms/step - loss: 0.3530 - accuracy: 0.8849 - val_loss: 0.3675 - val_accuracy: 0.8888\n",
      "Epoch 6/100\n",
      "11109/11109 [==============================] - 31s 3ms/step - loss: 0.3406 - accuracy: 0.8895 - val_loss: 0.3375 - val_accuracy: 0.8920\n",
      "Epoch 7/100\n",
      "11109/11109 [==============================] - 31s 3ms/step - loss: 0.3196 - accuracy: 0.8924 - val_loss: 0.3313 - val_accuracy: 0.8992\n",
      "Epoch 8/100\n",
      "11109/11109 [==============================] - 31s 3ms/step - loss: 0.3124 - accuracy: 0.8980 - val_loss: 0.3251 - val_accuracy: 0.8974\n",
      "Epoch 9/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.2974 - accuracy: 0.8983 - val_loss: 0.3222 - val_accuracy: 0.8945\n",
      "Epoch 10/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.2829 - accuracy: 0.9045 - val_loss: 0.3260 - val_accuracy: 0.8996\n",
      "Epoch 11/100\n",
      "11109/11109 [==============================] - 31s 3ms/step - loss: 0.2704 - accuracy: 0.9059 - val_loss: 0.3135 - val_accuracy: 0.8967\n",
      "Epoch 12/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.2669 - accuracy: 0.9087 - val_loss: 0.3532 - val_accuracy: 0.8938\n",
      "Epoch 13/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.2546 - accuracy: 0.9088 - val_loss: 0.3262 - val_accuracy: 0.9010\n",
      "Epoch 14/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.2449 - accuracy: 0.9131 - val_loss: 0.3408 - val_accuracy: 0.9010\n",
      "2778/2778 [==============================] - 3s 1ms/step\n",
      "12955/12955 [==============================] - 7s 538us/step\n",
      "FOLD: \n",
      "2778 11109\n",
      "Train on 11109 samples, validate on 2778 samples\n",
      "Epoch 1/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.8178 - accuracy: 0.7327 - val_loss: 0.4602 - val_accuracy: 0.8499\n",
      "Epoch 2/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.4768 - accuracy: 0.8473 - val_loss: 0.4130 - val_accuracy: 0.8744\n",
      "Epoch 3/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.4198 - accuracy: 0.8661 - val_loss: 0.3969 - val_accuracy: 0.8776\n",
      "Epoch 4/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.3867 - accuracy: 0.8793 - val_loss: 0.3762 - val_accuracy: 0.8837\n",
      "Epoch 5/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.3564 - accuracy: 0.8864 - val_loss: 0.3632 - val_accuracy: 0.8870\n",
      "Epoch 6/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.3374 - accuracy: 0.8914 - val_loss: 0.3622 - val_accuracy: 0.8819\n",
      "Epoch 7/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.3212 - accuracy: 0.8929 - val_loss: 0.3496 - val_accuracy: 0.8870\n",
      "Epoch 8/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.3051 - accuracy: 0.9001 - val_loss: 0.3548 - val_accuracy: 0.8902\n",
      "Epoch 9/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.2914 - accuracy: 0.9019 - val_loss: 0.3537 - val_accuracy: 0.8934\n",
      "Epoch 10/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.2794 - accuracy: 0.9040 - val_loss: 0.3493 - val_accuracy: 0.8931\n",
      "Epoch 11/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.2719 - accuracy: 0.9089 - val_loss: 0.3706 - val_accuracy: 0.8927\n",
      "Epoch 12/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.2593 - accuracy: 0.9143 - val_loss: 0.3656 - val_accuracy: 0.8920\n",
      "Epoch 13/100\n",
      "11109/11109 [==============================] - 32s 3ms/step - loss: 0.2564 - accuracy: 0.9108 - val_loss: 0.3631 - val_accuracy: 0.8956\n",
      "2778/2778 [==============================] - 2s 547us/step\n",
      "12955/12955 [==============================] - 7s 514us/step\n",
      "FOLD: \n",
      "2777 11110\n",
      "Train on 11110 samples, validate on 2777 samples\n",
      "Epoch 1/100\n",
      "11110/11110 [==============================] - 34s 3ms/step - loss: 0.8476 - accuracy: 0.7243 - val_loss: 0.4918 - val_accuracy: 0.8408\n",
      "Epoch 2/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.4813 - accuracy: 0.8506 - val_loss: 0.4378 - val_accuracy: 0.8624\n",
      "Epoch 3/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.4183 - accuracy: 0.8656 - val_loss: 0.4076 - val_accuracy: 0.8700\n",
      "Epoch 4/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3704 - accuracy: 0.8815 - val_loss: 0.3893 - val_accuracy: 0.8779\n",
      "Epoch 5/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3526 - accuracy: 0.8868 - val_loss: 0.3806 - val_accuracy: 0.8844\n",
      "Epoch 6/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3274 - accuracy: 0.8951 - val_loss: 0.3788 - val_accuracy: 0.8858\n",
      "Epoch 7/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3078 - accuracy: 0.8976 - val_loss: 0.3862 - val_accuracy: 0.8786\n",
      "Epoch 8/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.2959 - accuracy: 0.9008 - val_loss: 0.3951 - val_accuracy: 0.8837\n",
      "Epoch 9/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.2872 - accuracy: 0.9050 - val_loss: 0.3718 - val_accuracy: 0.8866\n",
      "Epoch 10/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.2730 - accuracy: 0.9084 - val_loss: 0.3860 - val_accuracy: 0.8833\n",
      "Epoch 11/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.2632 - accuracy: 0.9095 - val_loss: 0.3804 - val_accuracy: 0.8819\n",
      "Epoch 12/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.2573 - accuracy: 0.9128 - val_loss: 0.3734 - val_accuracy: 0.8848\n",
      "2777/2777 [==============================] - 2s 777us/step\n",
      "12955/12955 [==============================] - 7s 515us/step\n",
      "FOLD: \n",
      "2777 11110\n",
      "Train on 11110 samples, validate on 2777 samples\n",
      "Epoch 1/100\n",
      "11110/11110 [==============================] - 33s 3ms/step - loss: 0.8430 - accuracy: 0.7248 - val_loss: 0.4555 - val_accuracy: 0.8639\n",
      "Epoch 2/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.4914 - accuracy: 0.8470 - val_loss: 0.3828 - val_accuracy: 0.8815\n",
      "Epoch 3/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.4294 - accuracy: 0.8655 - val_loss: 0.3497 - val_accuracy: 0.8866\n",
      "Epoch 4/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3844 - accuracy: 0.8779 - val_loss: 0.3487 - val_accuracy: 0.8855\n",
      "Epoch 5/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3632 - accuracy: 0.8858 - val_loss: 0.3554 - val_accuracy: 0.8855\n",
      "Epoch 6/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3388 - accuracy: 0.8898 - val_loss: 0.3578 - val_accuracy: 0.8873\n",
      "Epoch 7/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3220 - accuracy: 0.8950 - val_loss: 0.3278 - val_accuracy: 0.8938\n",
      "Epoch 8/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3048 - accuracy: 0.8981 - val_loss: 0.3201 - val_accuracy: 0.8912\n",
      "Epoch 9/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.2979 - accuracy: 0.9000 - val_loss: 0.3243 - val_accuracy: 0.8909\n",
      "Epoch 10/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.2854 - accuracy: 0.9007 - val_loss: 0.3257 - val_accuracy: 0.8988\n",
      "Epoch 11/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.2754 - accuracy: 0.9072 - val_loss: 0.3421 - val_accuracy: 0.8977\n",
      "2777/2777 [==============================] - 2s 574us/step\n",
      "12955/12955 [==============================] - 7s 512us/step\n",
      "FOLD: \n",
      "2777 11110\n",
      "Train on 11110 samples, validate on 2777 samples\n",
      "Epoch 1/100\n",
      "11110/11110 [==============================] - 33s 3ms/step - loss: 0.8107 - accuracy: 0.7341 - val_loss: 0.4774 - val_accuracy: 0.8516\n",
      "Epoch 2/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.4813 - accuracy: 0.8485 - val_loss: 0.4074 - val_accuracy: 0.8776\n",
      "Epoch 3/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.4174 - accuracy: 0.8682 - val_loss: 0.3793 - val_accuracy: 0.8808\n",
      "Epoch 4/100\n",
      "11110/11110 [==============================] - 31s 3ms/step - loss: 0.3755 - accuracy: 0.8795 - val_loss: 0.3759 - val_accuracy: 0.8804\n",
      "Epoch 5/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3603 - accuracy: 0.8836 - val_loss: 0.3822 - val_accuracy: 0.8819\n",
      "Epoch 6/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3266 - accuracy: 0.8958 - val_loss: 0.3664 - val_accuracy: 0.8801\n",
      "Epoch 7/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3121 - accuracy: 0.8945 - val_loss: 0.3783 - val_accuracy: 0.8808\n",
      "Epoch 8/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.3031 - accuracy: 0.8987 - val_loss: 0.3840 - val_accuracy: 0.8822\n",
      "Epoch 9/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.2843 - accuracy: 0.9023 - val_loss: 0.3636 - val_accuracy: 0.8902\n",
      "Epoch 10/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.2756 - accuracy: 0.9080 - val_loss: 0.3801 - val_accuracy: 0.8884\n",
      "Epoch 11/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.2711 - accuracy: 0.9085 - val_loss: 0.3872 - val_accuracy: 0.8884\n",
      "Epoch 12/100\n",
      "11110/11110 [==============================] - 32s 3ms/step - loss: 0.2602 - accuracy: 0.9119 - val_loss: 0.3889 - val_accuracy: 0.8902\n",
      "2777/2777 [==============================] - 1s 527us/step\n",
      "12955/12955 [==============================] - 7s 512us/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "meta_train = np.zeros(shape = (len(train_seq),8))\n",
    "meta_test = np.zeros(shape = (len(test_seq),8))\n",
    "FLAG = True\n",
    "i = 0\n",
    "for tr_ind,te_ind in skf.split(train_labels):\n",
    "    i +=1\n",
    "    print('FOLD: '.format(i))\n",
    "    print(len(te_ind),len(tr_ind)) \n",
    "    model_name = 'benchmark_textcnn_fold_'+str(i)\n",
    "    X_train,X_train_label = train_seq[tr_ind],train_labels[tr_ind]\n",
    "    X_val,X_val_label     = train_seq[te_ind],train_labels[te_ind]\n",
    "    \n",
    "    model = TextCNN(max_len,max_cnt,embed_size,num_filters,kernel_size,conv_action,mask_zero)\n",
    "    \n",
    "    model_save_path = './NN/%s_%s.hdf5'%(model_name,embed_size)\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model_checkpoint = ModelCheckpoint(model_save_path, save_best_only=True, save_weights_only=True)\n",
    "    if TRAIN and FLAG:\n",
    "        model.fit(X_train,X_train_label,validation_data=(X_val,X_val_label),epochs=100,batch_size=64,shuffle=True,callbacks=[early_stopping,model_checkpoint] )\n",
    "    \n",
    "    model.load_weights(model_save_path)\n",
    "    pred_val = model.predict(X_val,batch_size=128,verbose=1)\n",
    "    pred_test = model.predict(test_seq,batch_size=128,verbose=1)\n",
    "    \n",
    "    meta_train[te_ind] = pred_val\n",
    "    meta_test += pred_test\n",
    "    K.clear_session()\n",
    "meta_test /= 5.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['prob0'] = 0\n",
    "test_df['prob1'] = 0\n",
    "test_df['prob2'] = 0\n",
    "test_df['prob3'] = 0\n",
    "test_df['prob4'] = 0\n",
    "test_df['prob5'] = 0\n",
    "test_df['prob6'] = 0\n",
    "test_df['prob7'] = 0\n",
    "\n",
    "test_df[['prob0','prob1','prob2','prob3','prob4','prob5','prob6','prob7']] = meta_test\n",
    "test_df[['file_id','prob0','prob1','prob2','prob3','prob4','prob5','prob6','prob7']].to_csv('nn_baseline_5fold.csv',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4054109a07366a15e0872477e08b55b91c055879d5d14672549f1c0c69ac48ed"
  },
  "kernelspec": {
   "display_name": "Tensorflow 2.1",
   "language": "python",
   "name": "tf2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
